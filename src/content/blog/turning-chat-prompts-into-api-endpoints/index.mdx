---
title: Turning chat prompts into api endpoints
description: Placeholder description
pubDate: 2025-01-13T11:44:50.233Z
heroImage: [./assets/hero.jpg, Playful visualization of JSON output]
heroImageCredit: [ChatGPT, ""]
isDraft: true
---

Recently, while in the OpenAI dashboard, updating the config for one of the [AI Assistants](https://platform.openai.com/docs/assistants/overview) in a [home maintenance app](https://www.starlinghome.co/) I'm working on, I came across a new and seemingly innocent-looking config option: [structured outputs](https://platform.openai.com/docs/guides/structured-outputs).

<figure>
  ![OpenAI Assistant Response
  Options](/images/blog/turning-chat-prompts-into-api-endpoints/assistant-response-options.png)
  <figcaption>OpenAI Assistant Response Options</figcaption>
</figure>

The feature isn't immediately obvious within the Assistant config, and to be honest, I actually came upon it by chance. But after starting to play with it, wow, was I blown away by the potential. In this blog post, I'll talk about why this updated output format is a big deal, an example use case, and some potentially not obvious factors to be aware of.

## From providing information to enabling features

The more conventional chat output, plain text, or in some cases, formatted text, is ideally suited for human consumption. It' intended to be read and used by a person.

(MAYBE INSERT TRADITIONAL CHAT EXAMPLE IMAGE)

Structured output, on the other hand, is to apps and computer programs what plain text is to people. It's what web apps normally consume, eg JSON via REST endpoints, etc. So when I am able to pre-define the structure of the response from an AI assistant, I have effectively turned the output into the basis for a service that the app can consume.

Put differently, I can use it like any other structured data source and effectively turn Assistant output into the basis for an app feature.

## A quick example

To better understand the power of structured output, let's look at a basic example.

If you are new to creating and using Assistants, they are configured at two key levels:

1. The general assistant instructions (or "system instructions"), which tells the assistant how they should respond to all specific prompts.
2. The assistant prompt, which is the specific instructions for one particular output.

Here's an example of this in which we use an Assistant to create a trivia game.

First, we add these general assistant instructions:

```markdown
Create a 3-question multiple choice trivia game. For each game, randomly select 5 common trivia game categories and create one question in each category. Ensure one correct answer per question and logical, plausible distractor choices.

Provide your response in JSON format using the following structure:

- `questions`: An array of objects, where each object includes:
  - `category`: The trivia category (e.g., "Music").
  - `question`: The trivia question.
  - `choices`: An array of answer choices.
  - `correctAnswer`: The correct answer.
```

Then, when we want to generate a new test, we submit this simple prompt:

```text
Create a new trivia game.
```

When we run this, we get this sample response:

```json
{
  "questions": [
    {
      "category": "Geography",
      "question": "Which country has the largest land area in the world?",
      "choices": ["Canada", "United States", "China", "Russia"],
      "correctAnswer": "Russia"
    },
    {
      "category": "Science",
      "question": "What is the chemical symbol for Gold?",
      "choices": ["Au", "Ag", "Fe", "Pb"],
      "correctAnswer": "Au"
    },
    {
      "category": "History",
      "question": "Who was the first President of the United States?",
      "choices": [
        "Abraham Lincoln",
        "George Washington",
        "Thomas Jefferson",
        "John Adams"
      ],
      "correctAnswer": "George Washington"
    }
  ]
}
```

Now, that may not seem like a big deal, but in fact, from the above output, we can create a fully working Trivia Game.

(INSERT SCREENSHOT OF TRIVIA GAME)

You can view the full source code for the game here, to get an idea of how you might make use of the structured output featured. (TODO: add source code link.)

This is just a toy example, but I am guessing you see the potential here. In some ways, structured output turns Assistants into a kind of infinite API that is only limited by your imagination. (TODO: use for callout?)

(MAYBE SOME KIND OF GIPHY HERE)

While digging into the structured output feature (in part through implementing the above trivia game), a few key considerations stood out:

- How you configure your assistant is turned upside down.
- Somewhat unintuitively, NOT selecting the Structured JSON output option is better.
- You'll need to add caching and generated IDs to turn it all into an app feature.

Let's look at each of these in more detail.

### How you configure your assistant is turned upside down

Normally, when configuring an Assistant, I find it to be best practice to provide broad assistant instructions and then provide specifics in each prompt. This makes sense because the specifics of what is requested are not known at the time of creating the assistant, but only at the point when submitting the prompt.

(INSERT EXAMPLE?)

However, what I realized when working with structured output is that you should turn this concept on its head. By configuring an assistant to provide structured output, you are effectively narrowing its purpose to a single use, as constrained by the output structure. Therefore, you should fully describe the use case in the general instructions and only use the prompt to request an instance of that output. If your use case accepts any variable values, then that would be included in the prompt and nothing more.

To better exaplain this, using our above Trivia game example, let's say we want to allow for a variable number of questions and have the option of restricting all questions to a specific category.

If so, we'd first update the general instructions accordingly, and then our prompt might look something like this:

```text
Create a new trivia game. Number of questions should be 10. All questions should be in the "Science" category.
```

With this approach, you can basically think of the assistant as the function and your prompt as calling the function and passing in any variables if needed.

## Somewhat unintuitively, NOT selecting the Structured JSON output option is better

Another aspect of working with structured output that led to some initial confusion was whether to use the `json_object` vs `json_schema` response option.

Initially, I figured that since I want output to be restricted to a specific shape that the schema option would be the way to go. While that may technically work, as it turns out, using the `json_object` is simpler to configure and, maybe more significantly, to tweak as needed.

In other words, as we saw in the above Trivia Game example, it is much simpler to define everything in one place, namely the general assistant instructions. With that approach, you can use a kind of plain english pseudo code to describe the desired shape, while if using the `json_schema` setting, you will need to conform to OpenAI's schema syntax.

So far, I have not found a good use case for using `json_schema` over `json_object`.

However, if you do decided to go with the schema option, I recommend letting the AI create the schema for you. Just explain what you want the assistant to do and that you want output in JSON format and the general shape of your desired output. Here is an example:

(insert example of generator instructions)

The Ai will then generate instructions optimized for an assistant. Be sure to read through the generated content carefully to ensure it matched what you intended.

One thing you definitely want to avoid is to have output shape instructions both in the general instructions as well as in the form of a schema, as that could result in some unexpected or odd output.

## Add caching and generated IDs to create features and endpoints

When I initially was playing around with the trivia game, I'd generate the game output, display the game ui and was able to play a game no problem. But at some point I made the "mistake" of refreshing my page, which resulted in my trivia game being replaced wiht a brand new game, as well as having to wait for all that to complete (usually 5-10 seconds) Obviously, that is not what we want. Once a game has been created, we want to ensure that specific game instance persists, at a minimum long enough to complete playing the game.

In other words, once a game has been generated, you need to store that specific instance, either just for the duration of the game, or maybe to allow for returning to the game at a later point.

We can't use the assistant output alone to achieve this, for at least a couple reasons. First, each time we prompt the assistant, we get a new game, and second, each prompt both takes time to generate a response, as well as incurs a token cost.

Therefore, in order to make structured prompt output usable as an app feature, we'll want to at least cache the output for short-term use, and possibly also store it in database, if we need longer-term persistence.

In my example app, I solved this by generating a unique id (I used NanoId but there are lots of other options, eg UUID) and then storing the game output in a Redis memory store. This allows for short-term persistence of a game instance.

The specifics of how you generate your id and persist the assistant output will vary depending on your use case, but you will definitely want to incorporate some type of persistence in your implementation.

See this code for an example of how I did it in the Trivia App.

## Conclustion

I'm very excited about the potential of this model but also keenly aware of the shortcomings. Hopefully, you'll discover some interesting use cases.
